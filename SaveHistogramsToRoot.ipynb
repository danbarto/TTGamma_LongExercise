{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load coffea output files and convert them to root files for use with the fitting programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea import hist, util\n",
    "from coffea.processor import accumulate\n",
    "import numpy as np\n",
    "import uproot\n",
    "import os\n",
    "\n",
    "from ttgamma.utils.plotting import RebinHist, SetRangeHist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your timestamps will differ (tip: pressing <Tab> will autocomplete)\n",
    "\n",
    "outputMC = accumulate(\n",
    "    [\n",
    "        util.load(\"Outputs/output_MCTTGamma_run20211216_114449.coffea\"),\n",
    "        util.load(\"Outputs/output_MCSingleTop_run20211216_124610.coffea\"),\n",
    "        util.load(\"Outputs/output_MCTTbar1l_run20211216_121317.coffea\"),\n",
    "        util.load(\"Outputs/output_MCTTbar2l_run20211216_122542.coffea\"),\n",
    "        util.load(\"Outputs/output_MCWJets_run20211216_142316.coffea\"),\n",
    "        util.load(\"Outputs/output_MCZJets_run20211216_130754.coffea\"),\n",
    "        util.load(\"Outputs/output_MCOther_run20211216_165125.coffea\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "outputData = util.load(\"Outputs/output_Data_run20211216_171828.coffea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get M3 distributions, grouped into top and non-top categories, saving to a root file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupingTop = {\n",
    "    \"TopPair\": [\n",
    "        \"TTGamma_Dilepton\",\n",
    "        \"TTGamma_SingleLept\",\n",
    "        \"TTGamma_Hadronic\",\n",
    "        \"TTbarPowheg_Dilepton\",\n",
    "        \"TTbarPowheg_Semilept\",\n",
    "        \"TTbarPowheg_Hadronic\",\n",
    "    ],\n",
    "    \"NonTop\": [\n",
    "        \"W1jets\",\n",
    "        \"W2jets\",\n",
    "        \"W3jets\",\n",
    "        \"W4jets\",\n",
    "        \"DYjetsM10to50\",\n",
    "        \"DYjetsM50\",\n",
    "        \"ST_s_channel\",\n",
    "        \"ST_tW_channel\",\n",
    "        \"ST_tbarW_channel\",\n",
    "        \"ST_tbar_channel\",\n",
    "        \"ST_t_channel\",\n",
    "        \"WGamma\",\n",
    "        \"ZGamma_01J_5f_lowMass\",\n",
    "        \"TTWtoLNu\",\n",
    "        \"TTWtoQQ\",\n",
    "        \"TTZtoLL\",\n",
    "        \"GJets_HT40To100\",\n",
    "        \"GJets_HT100To200\",\n",
    "        \"GJets_HT200To400\",\n",
    "        \"GJets_HT400To600\",\n",
    "        \"GJets_HT600ToInf\",\n",
    "#         \"QCD_Pt20to30_Ele\",\n",
    "#         \"QCD_Pt30to50_Ele\",\n",
    "#         \"QCD_Pt50to80_Ele\",\n",
    "#         \"QCD_Pt80to120_Ele\",\n",
    "#         \"QCD_Pt120to170_Ele\",\n",
    "#         \"QCD_Pt170to300_Ele\",\n",
    "#         \"QCD_Pt300toInf_Ele\",\n",
    "#         \"QCD_Pt20to30_Mu\",\n",
    "#         \"QCD_Pt30to50_Mu\",\n",
    "#         \"QCD_Pt50to80_Mu\",\n",
    "#         \"QCD_Pt80to120_Mu\",\n",
    "#         \"QCD_Pt120to170_Mu\",\n",
    "#         \"QCD_Pt170to300_Mu\",\n",
    "#         \"QCD_Pt300to470_Mu\",\n",
    "#         \"QCD_Pt470to600_Mu\",\n",
    "#         \"QCD_Pt600to800_Mu\",\n",
    "#         \"QCD_Pt800to1000_Mu\",\n",
    "#         \"QCD_Pt1000toInf_Mu\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "h = outputMC[\"M3\"].sum(\"lepFlavor\")\n",
    "h = h.group(\n",
    "    \"dataset\", hist.Cat(r\"dataset\", r\"Samples\", sorting=\"placement\"), groupingTop\n",
    ")\n",
    "h = h.sum(\"category\")\n",
    "h = RebinHist(h, \"M3\", 5)\n",
    "h = SetRangeHist(h, \"M3\", 50, 550)\n",
    "\n",
    "hData = outputData[\"M3\"].sum(\"lepFlavor\")\n",
    "hData = hData.sum(\"dataset\")\n",
    "hData = hData.sum(\"category\")\n",
    "hData = hData.sum(\"systematic\")\n",
    "hData = RebinHist(hData, \"M3\", 5)\n",
    "hData = SetRangeHist(hData, \"M3\", 50, 550)\n",
    "\n",
    "outdir = \"RootFiles\"\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "outputFile = uproot.recreate(os.path.join(outdir, \"M3_Output.root\"))\n",
    "\n",
    "outputFile[\"dataObs\"] = hData.to_hist()\n",
    "\n",
    "datasets = h.axis(\"dataset\").identifiers()\n",
    "systematics = h.axis(\"systematic\").identifiers()\n",
    "for _dataset in datasets:\n",
    "    for _systematic in systematics:\n",
    "        outputFile[f\"{_dataset}_{_systematic}\"] = h.integrate(\"dataset\", _dataset).integrate(\"systematic\", _systematic).to_hist()\n",
    "\n",
    "outputFile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get photon charged hadron isolation distributions, grouped into isolated and nonprompt categories, saving to a root file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupingPho = {\n",
    "    \"Isolated\": slice(1, 3),\n",
    "    \"NonPrompt\": slice(3, 5),\n",
    "}\n",
    "\n",
    "bins = np.array([0, 1.15, 2.5, 4.9, 9, 14.9, 20])\n",
    "\n",
    "h = outputMC[\"photon_chIso\"].sum(\"lepFlavor\")\n",
    "h = h.group(\n",
    "    \"category\", hist.Cat(r\"category\", r\"Samples\", sorting=\"placement\"), groupingPho\n",
    ")\n",
    "h = h.sum(\"dataset\")\n",
    "h = h.rebin(\"chIso\", hist.Bin(\"chIso\", h.axis(\"chIso\").label, bins))\n",
    "\n",
    "hData = outputData[\"photon_chIso\"].sum(\"lepFlavor\")\n",
    "hData = hData.sum(\"dataset\")\n",
    "hData = hData.sum(\"category\")\n",
    "hData = hData.sum(\"systematic\")\n",
    "hData = hData.rebin(\"chIso\", hist.Bin(\"chIso\", hData.axis(\"chIso\").label, bins))\n",
    "\n",
    "outputFile = uproot.recreate(os.path.join(outdir, \"Isolation_Output.root\"))\n",
    "outputFile[\"dataObs\"] = hData.to_hist()\n",
    "\n",
    "categories = h.axis(\"category\").identifiers()\n",
    "systematics = h.axis(\"systematic\").identifiers()\n",
    "for _category in categories:\n",
    "    for _systematic in systematics:\n",
    "        outputFile[f\"{_category}_{_systematic}\"] = (\n",
    "            h.integrate(\"category\", _category)\n",
    "            .integrate(\"systematic\", _systematic)\n",
    "            .to_hist()\n",
    "        )\n",
    "\n",
    "outputFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save distributions of e-gamma mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupingDataset = {\n",
    "    \"WGamma\": [\"WGamma\"],\n",
    "    \"ZGamma\": [\"ZGamma_01J_5f_lowMass\"],\n",
    "    \"Other\": [\n",
    "        \"TTGamma_Dilepton\",\n",
    "        \"TTGamma_SingleLept\",\n",
    "        \"TTGamma_Hadronic\",\n",
    "        \"TTbarPowheg_Dilepton\",\n",
    "        \"TTbarPowheg_Semilept\",\n",
    "        \"TTbarPowheg_Hadronic\",\n",
    "        \"W1jets\",\n",
    "        \"W2jets\",\n",
    "        \"W3jets\",\n",
    "        \"W4jets\",\n",
    "        \"DYjetsM50\",\n",
    "        \"DYjetsM10to50\",\n",
    "        \"ST_s_channel\",\n",
    "        \"ST_tW_channel\",\n",
    "        \"ST_tbarW_channel\",\n",
    "        \"ST_tbar_channel\",\n",
    "        \"ST_t_channel\",\n",
    "        \"TTWtoLNu\",\n",
    "        \"TTWtoQQ\",\n",
    "        \"TTZtoLL\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "groupingPho = {\n",
    "    \"Genuine\": slice(1, 2),\n",
    "    \"MisIDele\": slice(2, 3),\n",
    "    \"NonPrompt\": slice(3, 5),\n",
    "}\n",
    "\n",
    "\n",
    "h = outputMC[\"photon_lepton_mass_3j0t\"]\n",
    "h = h.group(\n",
    "    \"category\", hist.Cat(r\"category\", r\"Samples\", sorting=\"placement\"), groupingPho\n",
    ")\n",
    "h = h.group(\n",
    "    \"dataset\", hist.Cat(r\"dataset\", r\"Samples\", sorting=\"placement\"), groupingDataset\n",
    ")\n",
    "h = RebinHist(h, \"mass\", 5)\n",
    "h = SetRangeHist(h, \"mass\", 40, 200)\n",
    "\n",
    "hData = outputData[\"photon_lepton_mass_3j0t\"]\n",
    "hData = hData.sum(\"dataset\")\n",
    "hData = hData.sum(\"category\")\n",
    "hData = hData.sum(\"systematic\")\n",
    "hData = RebinHist(hData, \"mass\", 5)\n",
    "hData = SetRangeHist(hData, \"mass\", 40, 200)\n",
    "\n",
    "\n",
    "systematics = h.axis(\"systematic\").identifiers()\n",
    "\n",
    "for _lepton in [\"electron\", \"muon\"]:\n",
    "    outputFile = uproot.recreate(os.path.join(outdir, f\"MisID_Output_{_lepton}.root\"))\n",
    "\n",
    "    outputFile[\"dataObs\"] = hData.integrate(\"lepFlavor\", _lepton).to_hist()\n",
    "\n",
    "    hMisID = (\n",
    "        h.integrate(\"category\", \"MisIDele\")\n",
    "        .sum(\"dataset\")\n",
    "        .integrate(\"lepFlavor\", _lepton)\n",
    "    )\n",
    "    hOther = h.integrate(\"category\", [\"Genuine\", \"NonPrompt\"]).integrate(\n",
    "        \"lepFlavor\", _lepton\n",
    "    )\n",
    "    datasets = hOther.axis(\"dataset\").identifiers()\n",
    "\n",
    "    for _systematic in systematics:\n",
    "        outputFile[f\"MisIDele_{_systematic}\"] = hMisID.integrate(\n",
    "            \"systematic\", _systematic\n",
    "        ).to_hist()\n",
    "        for _dataset in datasets:\n",
    "            outputFile[f\"{_dataset}_{_systematic}\"] = (\n",
    "                hOther.integrate(\"dataset\", _dataset)\n",
    "                .integrate(\"systematic\", _systematic)\n",
    "                .to_hist()\n",
    "            )\n",
    "\n",
    "    outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
